{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from offroad.utils import load_state\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from car_dynamics.models_torch import MLP\n",
    "from car_dynamics.envs import make_env, KinematicBicycleModel, KinematicParams, DynamicBicycleModel, DynamicParams\n",
    "from car_dynamics.controllers_torch import MPPIController, rollout_fn_select, reward_track_fn\n",
    "import matplotlib.colors as colors\n",
    "from car_dynamics.models_torch import MLP, parse_data_end2end_norm \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "PROJ_DIR = '/Users/wenlixiao/Dropbox/School/Graduate/LeCAR/safe-learning-control/playground/offroad/'\n",
    "SPEED = 1.0\n",
    "LF = .16\n",
    "LR = .15\n",
    "L = LF+LR\n",
    "N_ROLLOUTS = 10000\n",
    "H = 4\n",
    "DT = 0.05\n",
    "SIGMA = 1.0\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log_dir = os.path.join(PROJ_DIR, 'data', 'data-20240131-195144') # drag\n",
    "log_dir = os.path.join(PROJ_DIR, 'data', 'data-20240229-114933') # counter \n",
    "# log_dir = os.path.join(PROJ_DIR, 'data', 'data-20240205-000620') # circle\n",
    "# log_dir = os.path.join(PROJ_DIR, 'data', 'sim-data-20240131-134617')\n",
    "with open(os.path.join(log_dir, 'header.json')) as f:\n",
    "    header_info = json.load(f)\n",
    "# t_list, p_dict, yaw_dict, action_list, controller_info = load_state(log_dir, [0, 144], orientation_provider=\"ORIENTATION_PROVIDOER\")\n",
    "t_list, p_dict, yaw_dict, action_list, controller_info = load_state(log_dir, [10, 81], orientation_provider=\"ORIENTATION_PROVIDOER\")\n",
    "# t_list, p_dict, yaw_dict, action_list, controller_info = load_state(log_dir, [0, 303], orientation_provider=\"ORIENTATION_PROVIDOER\")\n",
    "# t_list, p_dict, yaw_dict, action_list, controller_info = load_state(log_dir, [0, 1], orientation_provider=\"ORIENTATION_PROVIDOER\")\n",
    "obs_np = p_dict['obs']\n",
    "obs_np_1 = obs_np + .0\n",
    "targets = controller_info['targets']\n",
    "# targets = np.array([target[0] for target in controller_info['targets']])\n",
    "is_recover = controller_info['is_recover']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Bicycle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bea90aab9847098977ad42ec16c0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=570, description='N', max=3030), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(N=570)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = DynamicParams(\n",
    "                    num_envs=N_ROLLOUTS,\n",
    "                    DT=DT,\n",
    ")   \n",
    "\n",
    "\n",
    "dynamics = DynamicBicycleModel(model_params, device=DEVICE)\n",
    "rollout_fn = rollout_fn_select('dbm', dynamics, DT, L, LR)\n",
    "dynamics.reset()\n",
    "\n",
    "def rollout_start_kbm():\n",
    "    dynamics.reset()\n",
    "\n",
    "sigmas = torch.tensor([SIGMA] * 2)\n",
    "a_cov_per_step = torch.diag(sigmas**2)\n",
    "a_cov_init = a_cov_per_step.unsqueeze(0).repeat(H, 1, 1)\n",
    "# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "mppi = MPPIController(\n",
    "    gamma_mean=1.0,\n",
    "    gamma_sigma=0.0,\n",
    "    discount=1.0,\n",
    "    sample_sigma = 0.5,\n",
    "    lam = 0.01,\n",
    "    a_mean=torch.zeros(H, 2, device=DEVICE),\n",
    "    a_cov = a_cov_init.to(DEVICE),\n",
    "    n_rollouts=N_ROLLOUTS,\n",
    "    H=H,\n",
    "    device=DEVICE,\n",
    "    rollout_fn=rollout_fn,\n",
    "    a_min = [-1., -1],\n",
    "    a_max = [1., 1.],\n",
    "    a_mag = [.25, 1.],\n",
    "    a_shift= [0.25, 0.],\n",
    "    delay=0,\n",
    "    len_history=3,\n",
    "    rollout_start_fn=rollout_start_kbm,\n",
    "    debug=False,\n",
    "    fix_history=False\n",
    ")\n",
    "\n",
    "def plot(N=570):\n",
    "    target_N = np.array(targets[N])\n",
    "    for i in range(N):\n",
    "        mppi.feed_hist(obs_np[i, :4], torch.tensor(action_list[i, :2], device=DEVICE))\n",
    "\n",
    "    target_pos_tensor = torch.Tensor(targets[N]).to(DEVICE).squeeze(dim=-1)\n",
    "    action, mppi_info = mppi(obs_tensor[N, :4], reward_track_fn(target_pos_tensor, SPEED), vis_all_traj=True, vis_optim_traj=True)\n",
    "    all_traj = mppi_info['all_trajectory']\n",
    "    optim_traj = mppi_info['trajectory']\n",
    "    # plt.plot(obs_np[max(0,N-20):, 0], obs_np[max(0,N-20):, 1], alpha=0.5)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].plot(obs_np[:, 0], obs_np[:, 1], alpha=0.5)\n",
    "    for i in range(H+1):\n",
    "        axs[0].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2)\n",
    "    axs[0].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o')\n",
    "    for i in range(H+1):\n",
    "        axs[1].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2,)\n",
    "    axs[1].plot(target_N[:, 0], target_N[:, 1], 'pink', marker='^', label='reference')\n",
    "    axs[1].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', label='optim traj')\n",
    "    axs[1].plot(obs_np[N:N+H, 0], obs_np[N:N+H, 1], alpha=1, marker='x', color='black', label='real traj')\n",
    "    axs[1].set_aspect('equal')\n",
    "    axs[0].set_aspect('equal')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.suptitle(\"mppi-KBM\")\n",
    "interact(\n",
    "    plot,\n",
    "    N=(0, len(obs_np))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PROJ_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20240131-155022\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m dynamics_nn \u001b[38;5;241m=\u001b[39m MLP(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m\u001b[38;5;241m*\u001b[39mlen_history, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdynamics_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dynamics_nn\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m rollout_fn \u001b[38;5;241m=\u001b[39m rollout_fn_select(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn-end2end\u001b[39m\u001b[38;5;124m'\u001b[39m, dynamics_nn, DT, L, LR)\n",
      "File \u001b[0;32m~/Dropbox/School/Graduate/LeCAR/safe-learning-control/playground/car_dynamics/car_dynamics/models_torch/model.py:33\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(self, path, map_location)\u001b[0m\n\u001b[1;32m     30\u001b[0m combined_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(path, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Set the model state dict\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mcombined_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Update the model's spec dictionary\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec \u001b[38;5;241m=\u001b[39m combined_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state_dict'"
     ]
    }
   ],
   "source": [
    "len_history = 8\n",
    "model_dir = os.path.join(PROJ_DIR, 'tmp', '20240131-155022', 'model.pt')\n",
    "dynamics_nn = MLP(input_size=7*len_history, hidden_size=32, output_size=5)\n",
    "dynamics_nn.load(model_dir)\n",
    "dynamics_nn.to(DEVICE)\n",
    "rollout_fn = rollout_fn_select('nn-end2end', dynamics_nn, DT, L, LR)\n",
    "\n",
    "def rollout_start_nn():\n",
    "    ...\n",
    "\n",
    "sigmas = torch.tensor([SIGMA] * 2)\n",
    "a_cov_per_step = torch.diag(sigmas**2)\n",
    "a_cov_init = a_cov_per_step.unsqueeze(0).repeat(H, 1, 1)\n",
    "# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "mppi = MPPIController(\n",
    "    gamma_mean=1.0,\n",
    "    gamma_sigma=0.0,\n",
    "    discount=1.0,\n",
    "    sample_sigma = 0.5,\n",
    "    lam = 0.01,\n",
    "    a_mean=torch.zeros(H, 2, device=DEVICE),\n",
    "    a_cov = a_cov_init.to(DEVICE),\n",
    "    n_rollouts=N_ROLLOUTS,\n",
    "    H=H,\n",
    "    device=DEVICE,\n",
    "    rollout_fn=rollout_fn,\n",
    "    a_min = [-1., -1],\n",
    "    a_max = [1., 1.],\n",
    "    a_mag = [.05, 1.],\n",
    "    a_shift= [0.15, 0.],\n",
    "    delay=0,\n",
    "    len_history=len_history,\n",
    "    rollout_start_fn=rollout_start_nn,\n",
    ")\n",
    "\n",
    "def plot(N=300):\n",
    "    target_N = np.array(targets[N])\n",
    "    for i in range(N):\n",
    "        mppi.feed_hist(obs_np[i, :4], torch.tensor(action_list[i, :2], device=DEVICE))\n",
    "\n",
    "    target_pos_tensor = torch.Tensor(targets[N]).to(DEVICE).squeeze(dim=-1)\n",
    "    action, mppi_info = mppi(obs_np[N, :4], reward_track_fn(target_pos_tensor, SPEED), vis_all_traj=True, vis_optim_traj=True, use_nn=True)\n",
    "    all_traj = mppi_info['all_trajectory']\n",
    "    optim_traj = mppi_info['trajectory']\n",
    "    all_actions = mppi_info['action_candidate']\n",
    "    # plt.plot(obs_np[max(0,N-20):, 0], obs_np[max(0,N-20):, 1], alpha=0.5)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].plot(obs_np[:, 0], obs_np[:, 1], alpha=0.5)\n",
    "    for i in range(H+1):\n",
    "        axs[0].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2)\n",
    "    axs[0].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', )\n",
    "    axs[0].set_aspect('equal')\n",
    "    \n",
    "    for i in range(H+1):\n",
    "        axs[1].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2,)\n",
    "    axs[1].plot(target_N[:, 0], target_N[:, 1], 'pink', marker='^', label='reference')\n",
    "    axs[1].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', label='optim traj')\n",
    "    axs[1].plot(obs_np[N:N+H, 0], obs_np[N:N+H, 1], alpha=1, marker='x', color='black', label='real traj')\n",
    "    axs[1].set_aspect('equal')\n",
    "    h = axs[2].hist2d(all_actions[:, 0,0], all_actions[:, 0, 1],norm=colors.LogNorm(), bins=50)\n",
    "    fig.colorbar(h[3], ax=axs[2])\n",
    "    plt.suptitle(\"mppi-NN (Real)\")\n",
    "    plt.tight_layout()\n",
    "interact(\n",
    "    plot,\n",
    "    N=(555, 580, 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'debug' and 'fix_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m a_cov_init \u001b[38;5;241m=\u001b[39m a_cov_per_step\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(H, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m mppi \u001b[38;5;241m=\u001b[39m \u001b[43mMPPIController\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_sigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_cov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma_cov_init\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_rollouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_ROLLOUTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrollout_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrollout_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_mag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlen_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlen_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrollout_start_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrollout_start_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m     40\u001b[0m     target_N \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(targets[N])\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'debug' and 'fix_history'"
     ]
    }
   ],
   "source": [
    "len_history = 8\n",
    "model_dir = os.path.join(PROJ_DIR, 'tmp', '20240131-165751', 'model.pt')\n",
    "dynamics_nn = MLP(input_size=7*len_history, hidden_size=32, output_size=5)\n",
    "dynamics_nn.load(model_dir)\n",
    "dynamics_nn.to(DEVICE)\n",
    "rollout_fn = rollout_fn_select('nn-end2end', dynamics_nn, DT, L, LR)\n",
    "\n",
    "def rollout_start_nn():\n",
    "    ...\n",
    "\n",
    "sigmas = torch.tensor([SIGMA] * 2)\n",
    "a_cov_per_step = torch.diag(sigmas**2)\n",
    "a_cov_init = a_cov_per_step.unsqueeze(0).repeat(H, 1, 1)\n",
    "# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "mppi = MPPIController(\n",
    "    gamma_mean=1.0,\n",
    "    gamma_sigma=0.0,\n",
    "    discount=1.0,\n",
    "    sample_sigma = 0.5,\n",
    "    lam = 0.01,\n",
    "    a_mean=torch.zeros(H, 2, device=DEVICE),\n",
    "    a_cov = a_cov_init.to(DEVICE),\n",
    "    n_rollouts=N_ROLLOUTS,\n",
    "    H=H,\n",
    "    device=DEVICE,\n",
    "    rollout_fn=rollout_fn,\n",
    "    a_min = [-1., -1],\n",
    "    a_max = [1., 1.],\n",
    "    a_mag = [.25, 1.],\n",
    "    a_shift= [0.25, 0.],\n",
    "    delay=0,\n",
    "    len_history=len_history,\n",
    "    rollout_start_fn=rollout_start_nn,\n",
    ")\n",
    "\n",
    "def plot(N=300):\n",
    "    target_N = np.array(targets[N])\n",
    "    for i in range(N):\n",
    "        mppi.feed_hist(obs_np[i, :4], torch.tensor(action_list[i, :2], device=DEVICE))\n",
    "\n",
    "    target_pos_tensor = torch.Tensor(targets[N]).to(DEVICE).squeeze(dim=-1)\n",
    "    action, mppi_info = mppi(obs_np[N, :4], reward_track_fn(target_pos_tensor, SPEED), vis_all_traj=True, vis_optim_traj=True, use_nn=True)\n",
    "    all_traj = mppi_info['all_trajectory']\n",
    "    optim_traj = mppi_info['trajectory']\n",
    "    all_actions = mppi_info['action_candidate']\n",
    "    # plt.plot(obs_np[max(0,N-20):, 0], obs_np[max(0,N-20):, 1], alpha=0.5)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].plot(obs_np[:, 0], obs_np[:, 1], alpha=0.5)\n",
    "    for i in range(H+1):\n",
    "        axs[0].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2)\n",
    "    axs[0].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', )\n",
    "    axs[0].set_aspect('equal')\n",
    "    \n",
    "    for i in range(H+1):\n",
    "        axs[1].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2,)\n",
    "    axs[1].plot(target_N[:, 0], target_N[:, 1], 'pink', marker='^', label='reference')\n",
    "    axs[1].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', label='optim traj')\n",
    "    axs[1].plot(obs_np[N:N+H, 0], obs_np[N:N+H, 1], alpha=1, marker='x', color='black', label='real traj')\n",
    "    axs[1].set_aspect('equal')\n",
    "    axs[1].legend()\n",
    "    # axs[2].hist2d(all_actions[:, 0,0], all_actions[:, 0, 1],norm=colors.LogNorm())\n",
    "    plt.suptitle(\"mppi-NN (Mix 1:1)\")\n",
    "    plt.tight_layout()\n",
    "interact(\n",
    "    plot,\n",
    "    N=(0, len(obs_np))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([32, 56]) from checkpoint, the shape in current model is torch.Size([64, 14]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([5, 32]) from checkpoint, the shape in current model is torch.Size([5, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PROJ_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20240201-182437\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m dynamics_nn \u001b[38;5;241m=\u001b[39m MLP(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m\u001b[38;5;241m*\u001b[39mlen_history, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdynamics_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dynamics_nn\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m rollout_fn \u001b[38;5;241m=\u001b[39m rollout_fn_select(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn-end2end\u001b[39m\u001b[38;5;124m'\u001b[39m, dynamics_nn, DT, L, LR)\n",
      "File \u001b[0;32m~/car_dynamics/car_dynamics/models_torch/model.py:31\u001b[0m, in \u001b[0;36mMLP.load\u001b[0;34m(self, path, map_location)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/offroad/lib/python3.8/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([32, 56]) from checkpoint, the shape in current model is torch.Size([64, 14]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([5, 32]) from checkpoint, the shape in current model is torch.Size([5, 64])."
     ]
    }
   ],
   "source": [
    "len_history = 2\n",
    "model_dir = os.path.join(PROJ_DIR, 'tmp', '20240201-182437', 'model.pt')\n",
    "dynamics_nn = MLP(input_size=7*len_history, hidden_size=64, output_size=5)\n",
    "dynamics_nn.load(model_dir)\n",
    "dynamics_nn.to(DEVICE)\n",
    "rollout_fn = rollout_fn_select('nn-end2end', dynamics_nn, DT, L, LR)\n",
    "\n",
    "def rollout_start_nn():\n",
    "    ...\n",
    "\n",
    "sigmas = torch.tensor([SIGMA] * 2)\n",
    "a_cov_per_step = torch.diag(sigmas**2)\n",
    "a_cov_init = a_cov_per_step.unsqueeze(0).repeat(H, 1, 1)\n",
    "# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "mppi = MPPIController(\n",
    "    gamma_mean=1.0,\n",
    "    gamma_sigma=0.0,\n",
    "    discount=1.0,\n",
    "    sample_sigma = 0.5,\n",
    "    lam = 0.01,\n",
    "    a_mean=torch.zeros(H, 2, device=DEVICE),\n",
    "    a_cov = a_cov_init.to(DEVICE),\n",
    "    n_rollouts=N_ROLLOUTS,\n",
    "    H=H,\n",
    "    device=DEVICE,\n",
    "    rollout_fn=rollout_fn,\n",
    "    a_min = [-1., -1],\n",
    "    a_max = [1., 1.],\n",
    "    a_mag = [.25, 1.],\n",
    "    a_shift= [0.25, 0.],\n",
    "    delay=0,\n",
    "    len_history=len_history,\n",
    "    rollout_start_fn=rollout_start_nn,\n",
    ")\n",
    "\n",
    "def plot(N=300):\n",
    "    target_N = np.array(targets[N])\n",
    "    for i in range(N):\n",
    "        mppi.feed_hist(obs_np[i, :4], torch.tensor(action_list[i, :2], device=DEVICE))\n",
    "\n",
    "    target_pos_tensor = torch.Tensor(targets[N]).to(DEVICE).squeeze(dim=-1)\n",
    "    action, mppi_info = mppi(obs_np[N, :4], reward_track_fn(target_pos_tensor, SPEED), vis_all_traj=True, vis_optim_traj=True, use_nn=True)\n",
    "    all_traj = mppi_info['all_trajectory']\n",
    "    optim_traj = mppi_info['trajectory']\n",
    "    all_actions = mppi_info['action_candidate']\n",
    "    # plt.plot(obs_np[max(0,N-20):, 0], obs_np[max(0,N-20):, 1], alpha=0.5)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].plot(obs_np[:, 0], obs_np[:, 1], alpha=0.5)\n",
    "    for i in range(H+1):\n",
    "        axs[0].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2)\n",
    "    axs[0].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', )\n",
    "    axs[0].set_aspect('equal')\n",
    "    \n",
    "    for i in range(H+1):\n",
    "        axs[1].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2,)\n",
    "    axs[1].plot(target_N[:, 0], target_N[:, 1], 'pink', marker='^', label='reference')\n",
    "    axs[1].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', label='optim traj')\n",
    "    axs[1].plot(obs_np[N:N+H, 0], obs_np[N:N+H, 1], alpha=1, marker='x', color='black', label='real traj')\n",
    "    axs[1].set_aspect('equal')\n",
    "    axs[1].legend()\n",
    "    axs[2].hist2d(all_actions[:, 0,0], all_actions[:, 0, 1],norm=colors.LogNorm())\n",
    "    plt.suptitle(\"mppi-NN (Sim)\")\n",
    "    plt.tight_layout()\n",
    "interact(\n",
    "    plot,\n",
    "    N=(0, len(obs_np))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5267c30c328b4992b9ed58a4b9028c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=570, description='N', max=710), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(N=570)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_history = 3\n",
    "model_params = DynamicParams(\n",
    "                    num_envs=N_ROLLOUTS,\n",
    "                    DT=DT,\n",
    "                    Ta=10,\n",
    ")   \n",
    "\n",
    "\n",
    "dynamics = DynamicBicycleModel(model_params, device=DEVICE)\n",
    "rollout_fn = rollout_fn_select('dbm', dynamics, DT, L, LR)\n",
    "\n",
    "def rollout_start_nn():\n",
    "    ...\n",
    "\n",
    "SIGMA = 10.\n",
    "sigmas = torch.tensor([SIGMA] * 2)\n",
    "a_cov_per_step = torch.diag(sigmas**2)\n",
    "a_cov_init = a_cov_per_step.unsqueeze(0).repeat(H, 1, 1)\n",
    "# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "mppi = MPPIController(\n",
    "    gamma_mean=1.0,\n",
    "    gamma_sigma=0.0,\n",
    "    discount=1.,\n",
    "    sample_sigma = 0.5,\n",
    "    lam = 0.01,\n",
    "    a_mean=torch.zeros(H, 2, device=DEVICE),\n",
    "    a_cov = a_cov_init.to(DEVICE),\n",
    "    n_rollouts=N_ROLLOUTS,\n",
    "    H=H,\n",
    "    device=DEVICE,\n",
    "    rollout_fn=rollout_fn,\n",
    "    a_min = [-1., -1],\n",
    "    a_max = [1., 1.],\n",
    "    a_mag = [.075, 1.],\n",
    "    a_shift= [0.127, 0.],\n",
    "    delay=0,\n",
    "    len_history=len_history,\n",
    "    rollout_start_fn=rollout_start_nn,\n",
    "    debug=False,\n",
    "    fix_history=False,\n",
    "    num_actions=2,\n",
    "    num_obs=6,\n",
    ")\n",
    "\n",
    "def plot(N=570):\n",
    "    target_N = np.array(targets[N])\n",
    "    obs_tensor = torch.tensor(obs_np, device=DEVICE)\n",
    "    v_vec = ( obs_tensor[1:, :2] - obs_tensor[:-1, :2] ) / DT\n",
    "    vx = v_vec[:, 0] * torch.cos(obs_tensor[1:, 2]) + v_vec[:, 1] * torch.sin(obs_tensor[1:, 2])\n",
    "    vy = v_vec[:, 1] * torch.cos(obs_tensor[1:, 2]) - v_vec[:, 0] * torch.sin(obs_tensor[1:, 2])\n",
    "    omega = obs_tensor[1:,2] - obs_tensor[:-1,2]\n",
    "    omega = torch.atan2(torch.sin(omega), torch.cos(omega)) / DT\n",
    "    for i in range(1, N):\n",
    "        obs_t = torch.tensor([obs_tensor[i,0], obs_tensor[i,1],obs_tensor[i,2],vx[i-1],vy[i-1],omega[i-1]], device=DEVICE)\n",
    "        mppi.feed_hist(obs_t, torch.tensor(action_list[i, :2], device=DEVICE))\n",
    "\n",
    "\n",
    "    target_pos_tensor = torch.Tensor(targets[N]).to(DEVICE).squeeze(dim=-1)\n",
    "    obs_N = torch.tensor([obs_tensor[N,0], obs_tensor[N,1],obs_tensor[N,2],vx[N-1],vy[N-1],omega[N-1]], device=DEVICE)\n",
    "    action, mppi_info = mppi(obs_N, reward_track_fn(target_pos_tensor, SPEED), vis_all_traj=True, vis_optim_traj=True, use_nn=True)\n",
    "    all_traj = mppi_info['all_trajectory']\n",
    "    optim_traj = mppi_info['trajectory']\n",
    "    all_actions = mppi_info['action_candidate']\n",
    "    # plt.plot(obs_np[max(0,N-20):, 0], obs_np[max(0,N-20):, 1], alpha=0.5)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].plot(obs_np[:, 0], obs_np[:, 1], alpha=0.5)\n",
    "    # print(all_traj)\n",
    "    for i in range(H+1):\n",
    "        axs[0].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2)\n",
    "    axs[0].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', )\n",
    "    axs[0].set_aspect('equal')\n",
    "    \n",
    "    for i in range(H+1):\n",
    "        axs[1].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2,)\n",
    "    axs[1].plot(target_N[:, 0], target_N[:, 1], 'pink', marker='^', label='reference')\n",
    "    axs[1].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', label='optim traj')\n",
    "    axs[1].plot(obs_np[N:N+H, 0], obs_np[N:N+H, 1], alpha=1, marker='x', color='black', label='real traj')\n",
    "    axs[1].set_aspect('equal')\n",
    "    axs[1].legend()\n",
    "    # axs[2].hist2d(all_actions[:, 0,0], all_actions[:, 0, 1],norm=colors.LogNorm())\n",
    "    plt.suptitle(\"mppi-DBM\")\n",
    "    plt.tight_layout()\n",
    "interact(\n",
    "    plot,\n",
    "    N=(0, len(obs_np))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_traj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_traj\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_traj' is not defined"
     ]
    }
   ],
   "source": [
    "all_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def sig(x):\n",
    " return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/wenlixiao/Dropbox/School/Graduate/LeCAR/safe-learning-control/playground/offroad/tmp/20240212-101637/model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# model_dir = os.path.join(PROJ_DIR, 'tmp', '20240131-142206', 'model.pt')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dynamics_nn \u001b[38;5;241m=\u001b[39m MLP(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m\u001b[38;5;241m*\u001b[39mlen_history, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdynamics_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m dynamics_nn\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# rollout_fn = rollout_fn_select('nn-phyx-kbm', dynamics_nn, DT, L, LR)\u001b[39;00m\n",
      "File \u001b[0;32m~/Dropbox/School/Graduate/LeCAR/safe-learning-control/playground/car_dynamics/car_dynamics/models_torch/model.py:30\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(self, path, map_location)\u001b[0m\n\u001b[1;32m     27\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Load the combined dictionary\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m combined_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Set the model state dict\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(combined_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/rtk/lib/python3.8/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniforge3/envs/rtk/lib/python3.8/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniforge3/envs/rtk/lib/python3.8/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/wenlixiao/Dropbox/School/Graduate/LeCAR/safe-learning-control/playground/offroad/tmp/20240212-101637/model.pt'"
     ]
    }
   ],
   "source": [
    "len_history = 2\n",
    "# model_dir = os.path.join(PROJ_DIR, 'tmp', '20240211-171037', 'model.pt')\n",
    "model_dir = os.path.join(PROJ_DIR, 'tmp', '20240212-101637', 'model.pt')\n",
    "\n",
    "# model_dir = os.path.join(PROJ_DIR, 'tmp', '20240131-142206', 'model.pt')\n",
    "dynamics_nn = MLP(input_size=6*len_history, hidden_size=128, output_size=4)\n",
    "dynamics_nn.load(model_dir)\n",
    "dynamics_nn.to(DEVICE)\n",
    "# rollout_fn = rollout_fn_select('nn-phyx-kbm', dynamics_nn, DT, L, LR)\n",
    "rollout_fn = rollout_fn_select('nn-end2end', dynamics_nn, DT, L, LR)\n",
    "# rollout_fn = rollout_fn_select('nn-end2end-trunk', dynamics_nn, DT, L, LR)\n",
    "\n",
    "def rollout_start_nn():\n",
    "    ...\n",
    "\n",
    "sigmas = torch.tensor([SIGMA] * 2)\n",
    "a_cov_per_step = torch.diag(sigmas**2)\n",
    "a_cov_init = a_cov_per_step.unsqueeze(0).repeat(H, 1, 1)\n",
    "# a_cov_prev =  torch.full((H, 2, 2), 3.0**2) * torch.eye(2).unsqueeze(0).repeat(H, 1, 1)\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "mppi = MPPIController(\n",
    "    gamma_mean=1.0,\n",
    "    gamma_sigma=0.0,\n",
    "    discount=1,\n",
    "    sample_sigma = 0.5,\n",
    "    lam = 0.01,\n",
    "    a_mean=torch.zeros(H, 2, device=DEVICE),\n",
    "    a_cov = a_cov_init.to(DEVICE),\n",
    "    n_rollouts=N_ROLLOUTS,\n",
    "    H=H,\n",
    "    device=DEVICE,\n",
    "    rollout_fn=rollout_fn,\n",
    "    a_min = [-1., -1],\n",
    "    a_max = [1., 1.],\n",
    "    a_mag = [.25, 1.],\n",
    "    a_shift= [0.25, 0.],\n",
    "    delay=0,\n",
    "    len_history=len_history,\n",
    "    rollout_start_fn=rollout_start_nn,\n",
    "    debug=False,\n",
    "    fix_history=False,\n",
    ")\n",
    "\n",
    "def plot(N=570, show_idx=0):\n",
    "    target_N = np.array(targets[N])\n",
    "    for i in range(N):\n",
    "        mppi.feed_hist(obs_np[i, :4], torch.tensor(action_list[i, :2], device=DEVICE))\n",
    "\n",
    "    target_pos_tensor = torch.Tensor(targets[N]).to(DEVICE).squeeze(dim=-1)\n",
    "    action, mppi_info = mppi(obs_np[N, :4], reward_track_fn(target_pos_tensor, SPEED), vis_all_traj=True, vis_optim_traj=True, use_nn=True, nominal_actions = action_list[N:N+H+1, :2])\n",
    "    print(len(mppi_info['x_all']))\n",
    "    all_traj = mppi_info['all_trajectory']\n",
    "    optim_traj = mppi_info['trajectory']\n",
    "    all_actions = mppi_info['action_candidate']\n",
    "    optim_action = mppi_info['action']\n",
    "    \n",
    "    # plt.plot(obs_np[max(0,N-20):, 0], obs_np[max(0,N-20):, 1], alpha=0.5)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axs[0].plot(obs_np[:, 0], obs_np[:, 1], alpha=0.5)\n",
    "    for i in range(H+1):\n",
    "        axs[0].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2)\n",
    "    axs[0].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', )\n",
    "    axs[0].set_aspect('equal')\n",
    "    \n",
    "    for i in range(H+1):\n",
    "        axs[1].scatter(all_traj[i][:, 0], all_traj[i][:, 1], s=1, alpha=0.2,)\n",
    "    axs[1].plot(target_N[:, 0], target_N[:, 1], 'pink', marker='^', label='reference')\n",
    "    axs[1].plot(optim_traj[:, 0], optim_traj[:, 1], 'cyan', marker='o', label='optim traj')\n",
    "    axs[1].plot(obs_np[N:N+H+1, 0], obs_np[N:N+H+1, 1], alpha=1, marker='x', color='black', label='real traj')\n",
    "    axs[1].set_aspect('equal')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    axs[2].scatter(optim_action[0][0], optim_action[0][1], marker='o', color='cyan', label='optim action')\n",
    "    axs[2].scatter(action_list[N, 0], action_list[N, 1], marker='x', color='black', label='real action')\n",
    "    axs[2].set_xlim([0,1])\n",
    "    axs[2].set_ylim([-1,1])\n",
    "    axs[2].legend()\n",
    "    \n",
    "    # axs[2].hist2d(all_actions[:, 0,0], all_actions[:, 0, 1],norm=colors.LogNorm())\n",
    "    plt.suptitle(\"mppi-NN-phyx-kbm\")\n",
    "    plt.tight_layout()\n",
    "interact(\n",
    "    plot,\n",
    "    N=(0, len(obs_np)),\n",
    "    show_idx = [0,1,2,3],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f610dd760>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mppi_info['x_all'][0][-2:] == mppi_info['x_all'][2][-2:]\n",
    "y_all = np.array(mppi_info['y_all'])\n",
    "plt.plot(y_all[:100, 1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e2b89e9d954a0581549c927ed20aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='elev', max=90, min=-90), IntSlider(value=0, description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(elev, azim)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "PROJ_DIR = '/home/wenli-run/car_collect'\n",
    "log_dir = 'data/'\n",
    "dt = 0.05\n",
    "H = 4\n",
    "train_data_list = [\n",
    "#    dict(name='real-random', dir='data-20240201-200427', range=[5, 480]),\n",
    "#    dict(name='real-random', dir='data-20240201-202035', range=[5, 489]),\n",
    "#    dict(name='real-random', dir='data-20240201-221923', range=[5, 689]),\n",
    "   dict(name='sim-random', dir='sim-data-20240131-134617', range=[0, 1]),\n",
    "]\n",
    "X_train, _ = parse_data_end2end_norm(H, train_data_list, load_state, PROJ_DIR, log_dir, dt)\n",
    "X_test = torch.tensor(mppi_info['x_all'])\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "def pca(data, n_components):\n",
    "    # Centering the data (subtract the mean)\n",
    "    mean = torch.mean(data, 0)\n",
    "    data = data - mean.expand_as(data)\n",
    "\n",
    "    # SVD\n",
    "    U, S, V = torch.svd(torch.t(data))\n",
    "    return torch.mm(data, U[:, :n_components])\n",
    "\n",
    "# Apply PCA to both datasets (choose the number of components, e.g., 2)\n",
    "n_components = 3\n",
    "train_pca = pca(X_train_tensor, n_components)\n",
    "test_pca = pca(X_test_tensor, n_components)\n",
    "\n",
    "def plot(elev, azim):\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Scatter plot for training and testing data\n",
    "    ax.scatter(train_pca[:, 0], train_pca[:, 1], train_pca[:, 2], label='Sim Data', alpha=0.5, s=1)\n",
    "    ax.scatter(test_pca[:, 0], test_pca[:, 1], test_pca[:, 2], label='MPPI Data', alpha=0.1, s=1)\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.set_zlabel('Principal Component 3')\n",
    "    # elev = 30 # Elevation in degrees\n",
    "    # azim = 45 # Azimuthal angle in degrees\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    plt.legend()\n",
    "    plt.title('3D PCA of Training and Testing Datasets')\n",
    "    plt.show()\n",
    "interact(plot, elev=(-90, 90, 1), azim=(-180, 180, 1))\n",
    "\n",
    "# # Labels and title\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(train_pca[:, 0], train_pca[:, 1], label='Training Data', alpha=0.5, s=1)\n",
    "# plt.scatter(test_pca[:, 0], test_pca[:, 1], label='Testing Data', alpha=0.5, s=1)\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend()\n",
    "# plt.title('PCA of Training and Testing Datasets')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "offroad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
